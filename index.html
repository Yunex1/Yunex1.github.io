<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-zookeeper" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/zookeeper/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T07:49:49.572Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/19/zookeeper/">Zookeeper</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一-准备工作"><a href="#一-准备工作" class="headerlink" title="一.准备工作"></a>一.准备工作</h2><p>安装前需要安装好jdk</p>
<p>检测集群时间是否同步</p>
<p>检测防火墙是否关闭</p>
<p>检测主机 ip映射有没有配置</p>
<h2 id="二-解压zookeeper安装包"><a href="#二-解压zookeeper安装包" class="headerlink" title="二.解压zookeeper安装包"></a>二.解压zookeeper安装包</h2><p>在node1主机上，解压zookeeper的压缩包到&#x2F;export&#x2F;server路径下去，然后准备进行安装<br><img src="/../zookeeper/1.png" alt="图 1"></p>
<p>创建软连接<br><img src="/../zookeeper/2.png" alt="图 2"></p>
<h2 id="三-修改环境变量"><a href="#三-修改环境变量" class="headerlink" title="三.修改环境变量"></a>三.修改环境变量</h2><p>注意：三台虚拟机都要修改<br><img src="/../zookeeper/3.png" alt="图 3"><br><img src="/../zookeeper/4.png" alt="图 4"><br><img src="/../zookeeper/5.png" alt="图 5"></p>
<h2 id="四-修改配置文件"><a href="#四-修改配置文件" class="headerlink" title="四.修改配置文件"></a>四.修改配置文件</h2><p>修改zookeeper配置文件<br><img src="/../zookeeper/6.png" alt="图 6"></p>
<p>创建目录<br><img src="/../zookeeper/7.png" alt="图 7"></p>
<p>修改 zoo.cfg</p>
<p>增加下列内容<br><img src="/../zookeeper/8.png" alt="图 8"></p>
<h2 id="五-添加myid配置"><a href="#五-添加myid配置" class="headerlink" title="五.添加myid配置"></a>五.添加myid配置</h2><p>在node1主机的&#x2F;export&#x2F;data&#x2F;zookeeper&#x2F;zkdatas&#x2F;这个路径下创建一个文件，文件名为myid ,文件内容为1<br><img src="/../zookeeper/9.png" alt="图 9"></p>
<h2 id="六-安装包分发并修改myid的值"><a href="#六-安装包分发并修改myid的值" class="headerlink" title="六.安装包分发并修改myid的值"></a>六.安装包分发并修改myid的值</h2><p>在node1主机上，将安装包分发到其他机器第一台机器上面执行以下两个命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /export/server/apache-zookeeper-3.7.0-bin/ root@node2:/export/server/</span><br><span class="line">scp -r /export/server/apache-zookeeper-3.7.0-bin/ root@node3:/export/server/</span><br></pre></td></tr></table></figure>
<p><img src="/../zookeeper/10.png" alt="图 10"></p>
<p>第二台机器上建立软连接并修改myid的值</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server</span><br><span class="line">ln -s apache-zookeeper-3.7.0-bin/ zookeeper</span><br><span class="line">echo 2 &gt; /export/data/zookeeper/zkdatas/myid </span><br></pre></td></tr></table></figure>
<p><img src="/../zookeeper/11.png" alt="图 11"></p>
<p>第三台同理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server</span><br><span class="line">ln -s apache-zookeeper-3.7.0-bin/ zookeeper</span><br><span class="line">echo 3&gt; /export/data/zookeeper/zkdatas/myid </span><br></pre></td></tr></table></figure>
<p><img src="/../zookeeper/12.png" alt="图 12"></p>
<h2 id="七-三台机器启动zookeeper服务"><a href="#七-三台机器启动zookeeper服务" class="headerlink" title="七.三台机器启动zookeeper服务"></a>七.三台机器启动zookeeper服务</h2><p><img src="/../zookeeper/13.png" alt="图 13"><br><img src="/../zookeeper/14.png" alt="图 14"><br><img src="/../zookeeper/15.png" alt="图 15"><br><img src="/../zookeeper/16.png" alt="图 16"></p>
<p>编写一个shell脚本同时启动三台机器的zookeeper服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">if [ $# -eq 0 ] #  $#参数的个数</span><br><span class="line">then</span><br><span class="line">    echo &quot;please input param:start stop status&quot;</span><br><span class="line">else</span><br><span class="line">    if [ $1 = start  ]</span><br><span class="line">    then</span><br><span class="line">        for i in &#123;1..3&#125;</span><br><span class="line">        do</span><br><span class="line">            echo &quot;$&#123;1&#125;ing node$&#123;i&#125;&quot;</span><br><span class="line">            ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh start&quot;</span><br><span class="line">        done</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    if [ $1 = stop ]</span><br><span class="line">    then</span><br><span class="line">        for i in &#123;1..3&#125;</span><br><span class="line">        do</span><br><span class="line">            echo &quot;$&#123;1&#125;ping node$&#123;i&#125;&quot;</span><br><span class="line">            ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh stop&quot;</span><br><span class="line">        done</span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line">    if [ $1 = status ]</span><br><span class="line">    then</span><br><span class="line">        for i in &#123;1..3&#125;</span><br><span class="line">        do</span><br><span class="line">            echo &quot;node$&#123;i&#125; status:&quot;</span><br><span class="line">            ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh status&quot;</span><br><span class="line">        done</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p><img src="/../zookeeper/17.png" alt="图 17"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/zookeeper/" data-id="clj2k5f2a000al0vf4rk32l29" data-title="Zookeeper" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-kafka" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/kafka/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T07:49:14.563Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/19/kafka/">Kafka</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-安装kafka-集群"><a href="#1-安装kafka-集群" class="headerlink" title="1. 安装kafka 集群"></a>1. 安装kafka 集群</h2><p>上传压缩包到&#x2F;export&#x2F;server目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv kafka_2.12-2.4.1.tgz /export/server</span><br></pre></td></tr></table></figure>

<p>解压</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.12-2.4.1.tgz</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/1.png" alt="图 1"></p>
<p>进入配置文件目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/kafka_2.11-2.0.0/config</span><br></pre></td></tr></table></figure>

<p>编辑配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi server.properties</span><br></pre></td></tr></table></figure>

<p>加入以下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#为依次增长的:0、1、2、3、4,集群中唯一 id --》从0开始，每台不能重复，第一块要改的</span><br><span class="line">broker.id=0 </span><br><span class="line"></span><br><span class="line">----Logbasic------</span><br><span class="line">#数据存储的目录，第二块要改的</span><br><span class="line">log.dirs=/export/data/kafka-logs  </span><br><span class="line"></span><br><span class="line">---zookeeper----</span><br><span class="line">#指定 zk 集群地址，第四块要改的</span><br><span class="line">zookeeper.connect=node1:2181,node2:2181,node3:2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/2.png" alt="图 2"></p>
<p>将node1内容分发到node2，node3中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Scp -r /export/server/kafka_2.12-2.4.1 root@node2: /export/server</span><br><span class="line">Scp -r /export/server/kafka_2.12-2.4.1 root@node3: /export/server</span><br></pre></td></tr></table></figure>

<p>配置环境变量</p>
<p>进入profile</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile </span><br></pre></td></tr></table></figure>

<p>添加以下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export KAFKA_HOME=/export/server/kafka </span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/3.png" alt="图 3"></p>
<p>添加后重置环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<p>分发环境变量至node2，node3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Scp /etc/profile root@node2: /etc/profile</span><br><span class="line">Scp /etc/profile root@node3: /etc/profile</span><br></pre></td></tr></table></figure>

<p>分别在node2和node3上修改配置文件</p>
<p>broker.id&#x3D;1<br><img src="/../kafka/4.png" alt="图 4"></p>
<p>broker.id&#x3D;2<br><img src="/../kafka/5.png" alt="图 5"></p>
<p>启停集群(在各个节点上启动)</p>
<p>启动集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh -daemon /export/server/kafka/config/server.properties</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/6.png" alt="图 6"></p>
<p>停止集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-stop.sh stop</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/7.png" alt="图 7"></p>
<p>kafka一键启停脚本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">!/bin/bash</span><br><span class="line">if [ $# -eq 0 ]</span><br><span class="line">then</span><br><span class="line">echo &quot;please input param:start stop&quot;</span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">if [ $1 = start  ]</span><br><span class="line">then</span><br><span class="line">for i in &#123;1..3&#125;</span><br><span class="line">do</span><br><span class="line">echo &quot;$&#123;1&#125;ing node$&#123;i&#125;&quot;</span><br><span class="line">ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/kafka/bin/kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span><br><span class="line">done</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ $1 = stop ]</span><br><span class="line">then</span><br><span class="line">for i in &#123;1..3&#125;</span><br><span class="line">do</span><br><span class="line">ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/kafka/bin/kafka-server-stop.sh&quot;</span><br><span class="line">done</span><br><span class="line">fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/8.png" alt="图 8"></p>
<h2 id="2-kafka命令行操作"><a href="#2-kafka命令行操作" class="headerlink" title="2.kafka命令行操作"></a>2.kafka命令行操作</h2><h3 id="（1）创建topic"><a href="#（1）创建topic" class="headerlink" title="（1）创建topic"></a>（1）创建topic</h3><p>基本方式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --create --topic tpc_1 --partitions 2 --replication-factor 2 --zookeeper node1:2181</span><br></pre></td></tr></table></figure>
<p>bootstrap方式</p>
<p>创建名为test的主题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --bootstrap-server node1:9092 --topic test</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/9.png" alt="图 9"></p>
<p>查看目前Kafka中的主题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --bootstrap-server node1:9092</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/10.png" alt="图 10"></p>
<p>删除topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh  --delete --topic tpc_1 --zookeeper node1：2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/11.png" alt="图 11"></p>
<p>(1)列出当前系统中的所有 topic </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181 --list</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/12.png" alt="图 12"></p>
<p>(2)查看 topic 详细信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --topic tpc_1   --zookeeper node1:2181 --replica-assignment 0:1,1:2</span><br><span class="line">bin/kafka-topics.sh --describe --topic tpc_1 --zookeper node1:2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/13.png" alt="图 13"></p>
<p>增加分区数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --alter --topic tpc_1 --partitions 3 --zookeeper node1:2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/14.png" alt="图 14"></p>
<p>消费消息(从头开始)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server node1:9092, node2:9092, node1:9092 --topic tpc_1 --from-beginning</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/15.png" alt="图 15"></p>
<p>指定要消费的分区,和要消费的起始 offset </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server node1:9092,node2:9092,node3:9092 --topic tcp_1 --offset 2 --partition 0</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/16.png" alt="图 16"><br><img src="/../kafka/17.png" alt="图 17"></p>
<h3 id="（2）配置管理-kafka-configs"><a href="#（2）配置管理-kafka-configs" class="headerlink" title="（2）配置管理 kafka-configs"></a>（2）配置管理 kafka-configs</h3><p>查看 topic 的配置可以按如下方式执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh zookeeper node1: 2181 --describe --entity-type topics --entity-name tpc_2</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/18.png" alt="图 18"></p>
<p>查看 broker 的动态配置可以按如下方式执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh zookeeper node1: 2181 --describe --entity-type brokers --entity-name 0 --zookeeper node1:2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafka/19.png" alt="图 19"></p>
<h3 id="（3）IDEA案例"><a href="#（3）IDEA案例" class="headerlink" title="（3）IDEA案例"></a>（3）IDEA案例</h3><p>生产信息<br><img src="/../kafka/20.png" alt="图 20"><br><img src="/../kafka/21.png" alt="图 21"><br><img src="/../kafka/22.png" alt="图 22"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/kafka/" data-id="clj2k5f290008l0vf5wzfajjc" data-title="Kafka" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-sqoop" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/sqoop/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T05:47:10.621Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/19/sqoop/">Sqoop</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1、sqoop安装"><a href="#1、sqoop安装" class="headerlink" title="1、sqoop安装"></a>1、sqoop安装</h2><p>1.1将sqoop包上传至虚拟机<br><img src="/../sqoop/1.png" alt="图 1"><br>输入解压命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /export/server/</span><br></pre></td></tr></table></figure>
<p>解压至&#x2F;export&#x2F;server&#x2F;目录下，并输入ln -s 配置软连接<br><img src="/../sqoop/2.png" alt="图 2"></p>
<p>1.2修改配置文件</p>
<p>vim &#x2F;etc&#x2F;profile，输入sqoop的运行路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#SQOOP_HOME</span><br><span class="line">export SQOOP_HOME=/export/server/sqoop</span><br><span class="line">export PATH=$PATH:$SQOOP_HOME/bin</span><br></pre></td></tr></table></figure>
<p><img src="/../sqoop/3.png" alt="图 3"></p>
<p>Source profile</p>
<p>Cd到sqoop的conf目录下，将sqoop-env-templa.sh修改为sqoop-env.sh<br><img src="/../sqoop/4.png" alt="图 4"></p>
<p>vim进入sqoop-env.sh输入配置信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_COMMON_HOME= /export/server/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME= /export/server/hadoop</span><br><span class="line">export HIVE_HOME= /export/server/hive</span><br></pre></td></tr></table></figure>
<p><img src="/../sqoop/5.png" alt="图 5"></p>
<p>加入mysql的jdbc驱动包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp /export/server/hive/lib/mysql-connector-java-5.1.32.jar </span><br><span class="line">$SQOOP_HOME/lib/</span><br></pre></td></tr></table></figure>
<p><img src="/../sqoop/6.png" alt="图 6"></p>
<p>1.3验证启动</p>
<p>Cd到sqoop目录下，输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop list-databases \</span><br><span class="line"> --connect jdbc:mysql://node1:3306/ \   #链接地址node1上的mysql</span><br><span class="line"> 	 --username root --password hadoop     #输入mysql的密码</span><br></pre></td></tr></table></figure>
<p>列出所有mysql的数据库<br><img src="/../sqoop/7.png" alt="图 7"></p>
<h2 id="2-sqoop导入至HDFS"><a href="#2-sqoop导入至HDFS" class="headerlink" title="2.sqoop导入至HDFS"></a>2.sqoop导入至HDFS</h2><h3 id="2-1创建数据库和建表"><a href="#2-1创建数据库和建表" class="headerlink" title="2.1创建数据库和建表"></a>2.1创建数据库和建表</h3><p> 2.1.1链接node1 mysql数据库后，在Navicat中新建库get_food，使用以下SQL语句创建数据表<br> <img src="/../sqoop/8.png" alt="图 8"></p>
<p> 2.1.2插入数据<br> <img src="/../sqoop/9.png" alt="图 9"></p>
<p> 2.1.3查看数据表中数据<br> <img src="/../sqoop/10.png" alt="图 10"></p>
<h3 id="2-2上传至DFFS"><a href="#2-2上传至DFFS" class="headerlink" title="2.2上传至DFFS"></a>2.2上传至DFFS</h3><p>2.2.1上传数据</p>
<p>输入以下命令<br><img src="/../sqoop/11.png" alt="图 11"></p>
<p>2.2.2查看数据</p>
<p>进入node1:&#x2F;&#x2F;9870的HDFS页面查看<br><img src="/../sqoop/12.png" alt="图 12"><br>在node1上使用-cat命令查看<br><img src="/../sqoop/13.png" alt="图 13"><br>导入成功</p>
<p>更新导出(updateonly)<br><img src="/../sqoop/14.png" alt="图 14"><br><img src="/../sqoop/15.png" alt="图 15"><br><img src="/../sqoop/16.png" alt="图 16"><br><img src="/../sqoop/17.png" alt="图 17"><br><img src="/../sqoop/18.png" alt="图 18"><br>更新导出(allowinsert)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/sqoop/" data-id="clj2k5f290009l0vfbx22ho41" data-title="Sqoop" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-flume" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/flume/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T05:21:40.884Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/19/flume/">Flume</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>将apache-flume-1.9.0-bin.tar.gz下载到CentOS系统中，对其解压</p>
<p>解压命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xzf apache-flume-1.9.0-bin.tar.gz</span><br></pre></td></tr></table></figure>

<p>添加软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s apache-flume-1.9.0-bin flume</span><br></pre></td></tr></table></figure>

<p>Flume使用需要依赖JDK1.8以上环境，确保已安装</p>
<p>将Flume安装目录配置到PATH中，方便在任意目录使用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></table></figure>

<p>添加以下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#FLUME_HOME</span><br><span class="line">export FLUME_HOME=/export/server/flume</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/1.png" alt="图 1"></p>
<p>保存成功后刷新</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<p>查看是否设置成功</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $FLUME_HOME</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/2.png" alt="图 2"></p>
<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h3 id="一、入门使用示例"><a href="#一、入门使用示例" class="headerlink" title="一、入门使用示例"></a>一、入门使用示例</h3><p>1、	安装Netcat</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nc</span><br></pre></td></tr></table></figure>

<p>2、	在flume&#x2F;myconf目录下添加配置文件netcat-logger.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># example1-netcat-logger.conf: 单节点Flume配置</span><br><span class="line"># 定义agent名称为a1</span><br><span class="line"># 设置3个组件的名称</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># 配置source类型为NetCat,监听地址为本机，端口为44444</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = 0.0.0.0</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line">#source和channel关联</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line"></span><br><span class="line"># 配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 配置sink类型为Logger</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"># 将sink绑定到channel上</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/3.png" alt="图 3"></p>
<p>3、	启动agent</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/example1-netcat-logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/4.png" alt="图 4"></p>
<p>4、	使用Netcat测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">从另一个终端启动Netcat连接到44444端口，发送一些字符串</span><br><span class="line">nc node1 44444</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/5.png" alt="图 5"></p>
<p>观察agent控制台<br><img src="/../flume/6.png" alt="图 6"></p>
<h3 id="二、exec-source测试"><a href="#二、exec-source测试" class="headerlink" title="二、exec_source测试"></a>二、exec_source测试</h3><p>1、	配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">vim exec-source-logger.conf</span><br><span class="line"></span><br><span class="line"># example2-exec-source-logger.conf</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sources.r1.command = tail -F /export/data/flume-example-data/shell/access.log </span><br><span class="line">a1.sources.r1.batchSize = 100</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/7.png" alt="图 7"></p>
<p>2、	启动测试</p>
<p>（1）准备一个日志文件</p>
<p>（2）写一个脚本模拟往日志文件中持续写入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for i in &#123;1..10000&#125;; </span><br><span class="line">do echo $&#123;i&#125; “bigdata log”  &gt;&gt;  access.log ; </span><br><span class="line">sleep 0.5; </span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/8.png" alt="图 8"></p>
<p>（3）创建一个flume自定义配置文件</p>
<p>（4）启动flume采集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf/ -f myconf/example2-exec-source-logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/9.png" alt="图 9"></p>
<h3 id="三、spooldir-source测试"><a href="#三、spooldir-source测试" class="headerlink" title="三、spooldir_source测试"></a>三、spooldir_source测试</h3><p>1、	配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">vim spooldir-source.conf</span><br><span class="line"></span><br><span class="line">#example3-spooldir-source.conf</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sources.r1.type = spooldir</span><br><span class="line">a1.sources.r1.spoolDir = /export/data/flume-example-data/weblog </span><br><span class="line"></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/10.png" alt="图 10"></p>
<p>2、	启动测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/example3-spooldir-source.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/11.png" alt="图 11"></p>
<h3 id="四、taildir-source测试"><a href="#四、taildir-source测试" class="headerlink" title="四、taildir_source测试"></a>四、taildir_source测试</h3><p>1、	配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">vim taildir-source.conf</span><br><span class="line"></span><br><span class="line">#example4-taildir-source.conf</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sources.r1.positionFile = /export/data/flume-example-data/flumedata/taildir_position.json</span><br><span class="line">a1.sources.r1.filegroups = g1 g2</span><br><span class="line">a1.sources.r1.filegroups.g1 = /export/data/flume-example-data/weblog/web.*</span><br><span class="line">a1.sources.r1.filegroups.g2 = /export/data/flume-example-data/wxlog/wx.*</span><br><span class="line">a1.sources.r1.fileHeader = true</span><br><span class="line">#动态的header-keys eg：filepath=/../../../</span><br><span class="line">a1.sources.r1.fileHeaderKey = filepath</span><br><span class="line"></span><br><span class="line">#写死的header-keys（静态的） eg:a1 = aa1</span><br><span class="line">a1.sources.r1.headers.g1.a1 = aa1</span><br><span class="line">a1.sources.r1.headers.g1.b1 = bb1</span><br><span class="line">a1.sources.r1.headers.g2.a2 = aa2</span><br><span class="line">a1.sources.r1.headers.g2.b2 = bb2</span><br><span class="line"></span><br><span class="line">a1.sources.r1.maxBatchCount = 1000</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 10000</span><br><span class="line">a1.channels.c1.transactionCapacity = 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/12.png" alt="图 12"></p>
<p>2、	启动测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf/ -f  myconf/example4-taildir-source.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/13.png" alt="图 13"></p>
<h3 id="五、avro-source"><a href="#五、avro-source" class="headerlink" title="五、avro source"></a>五、avro source</h3><p>1、	配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">vim avro-source.conf</span><br><span class="line"></span><br><span class="line">#example5-avro-source.conf</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sources.r1.bind = 0.0.0.0</span><br><span class="line">a1.sources.r1.port = 4141</span><br><span class="line"></span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 200</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/14.png" alt="图 14"></p>
<p>2、	启动测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -c conf -f  myconf/example5-avro-source.conf -n a1 -Dflume.root.logger=INFO,console  </span><br></pre></td></tr></table></figure>
<p><img src="/../flume/15.png" alt="图 15"></p>
<h3 id="六、使用File-Channel实现数据持久化"><a href="#六、使用File-Channel实现数据持久化" class="headerlink" title="六、使用File Channel实现数据持久化"></a>六、使用File Channel实现数据持久化</h3><p>1、	配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">vim file-channel.conf</span><br><span class="line"></span><br><span class="line">#example6-file-channel.conf</span><br><span class="line"># 定义agent名称为a1</span><br><span class="line"># 设置3个组件的名称</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"># 多个channel使用空格分隔</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line"></span><br><span class="line"># 配置source类型为NetCat,监听地址为本机，端口为44444</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = 0.0.0.0</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># 配置sink类型为Logger</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># 配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 配置FileChannel,checkpointDir为检查点文件存储目录，dataDirs为日志数据存储目录，</span><br><span class="line">a1.channels.c2.type = file</span><br><span class="line">a1.channels.c2.checkpointDir = /export/data/flume-example-data/flumedata/checkpoint_filechannel</span><br><span class="line">a1.channels.c2.dataDirs = /export/data/flume-example-data/flumedata/data_filechannel</span><br><span class="line"></span><br><span class="line"># 将source和sink绑定到channel上</span><br><span class="line"># source同时绑定到c1和c2上</span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/16.png" alt="图 16"></p>
<p>2、	启动flume</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/example6-file-channel.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/17.png" alt="图 17"></p>
<h3 id="七、利用avro-source和avro-sink实现agent级联"><a href="#七、利用avro-source和avro-sink实现agent级联" class="headerlink" title="七、利用avro source和avro sink实现agent级联"></a>七、利用avro source和avro sink实现agent级联</h3><p>1、	配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">vim taildir-f-avro.conf</span><br><span class="line"></span><br><span class="line">#上游服务器配置 example7-1-taildir-f-avro.conf</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sources.r1.positionFile = /export/data/flume-example-data/flumedata/taildir_position.json</span><br><span class="line">a1.sources.r1.filegroups = g1 g2</span><br><span class="line">a1.sources.r1.filegroups.g1 = /export/data/flume-example-data/weblog/web.*</span><br><span class="line">a1.sources.r1.filegroups.g2 = /export/data/flume-example-data/wxlog/wx.*</span><br><span class="line">#提高吞吐量</span><br><span class="line">a1.sources.r1.batchSize = 1000</span><br><span class="line">#动态的header-keys eg：filepath=/../../../</span><br><span class="line">a1.sources.r1.fileHeaderKey = filepath</span><br><span class="line"></span><br><span class="line">#拦截器配置，添加header=timestamp</span><br><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type = timestamp</span><br><span class="line">a1.sources.r1.interceptors.i1.headerName = timestamp</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type = file</span><br><span class="line">#本机数据汇集检查点、event存储目录</span><br><span class="line">a1.channels.c1.checkpointDir = /export/data/flume-example-data/flumedata/checkpoint</span><br><span class="line">a1.channels.c1.dataDirs = /export/data/flume-example-data/flumedata/data</span><br><span class="line">a1.channels.c1.transactionCapacity = 2000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.batch-size = 1000</span><br><span class="line">#下游目标主机、端口</span><br><span class="line">a1.sinks.k1.hostname = node3</span><br><span class="line">a1.sinks.k1.port = 44444</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/18.png" alt="图 18"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">vim avro-f-hdfs.conf</span><br><span class="line"></span><br><span class="line">#下游服务器配置 example7-2-avro-f-hdfs.conf</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line">#下游数据汇集avro source</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sources.r1.bind = 0.0.0.0</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line">a1.sources.r1.threads = 10</span><br><span class="line">a1.sources.r1.batchSize = 1000</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type = file</span><br><span class="line">a1.channels.c1.checkpointDir = /export/data/flume-example-data/flumedata/checkpoint</span><br><span class="line">a1.channels.c1.dataDirs = /export/data/flume-example-data/flumedata/data</span><br><span class="line">a1.channels.c1.transactionCapacity = 2000</span><br><span class="line"></span><br><span class="line">#hdfs sink</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://node1:8020/logdata/%Y-%m-%d/%H/</span><br><span class="line">#eg：文件名 logdata_34438hxfd.log，在滚动时，logdata_34438hxfd.log.tmp</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = logdata_</span><br><span class="line">a1.sinks.k1.hdfs.fileSuffix = .log</span><br><span class="line"></span><br><span class="line">#三个条件没有优先级，谁先达到就进行滚动</span><br><span class="line">#按时间间隔滚动</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 0</span><br><span class="line">#按文件大小滚动 256MB</span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 268435456</span><br><span class="line">#按event条数滚动</span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 100000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.batchSize = 1000</span><br><span class="line">a1.sinks.k1.hdfs.codeC = gzip</span><br><span class="line">a1.sinks.k1.hdfs.fileType = CompressedStream</span><br></pre></td></tr></table></figure>
<p><img src="/../flume/19.png" alt="图 19"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/flume/" data-id="clj2k5f280007l0vfcmvrhb8k" data-title="Flume" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark(Yarn)" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/09/Spark(Yarn)/" class="article-date">
  <time class="dt-published" datetime="2023-06-09T04:41:48.191Z" itemprop="datePublished">2023-06-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/09/Spark(Yarn)/">Spark(Yarn)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Spark-On-YARN-环境搭建部署"><a href="#Spark-On-YARN-环境搭建部署" class="headerlink" title="Spark On YARN 环境搭建部署"></a>Spark On YARN 环境搭建部署</h1><h2 id="1、配置spark-env-sh"><a href="#1、配置spark-env-sh" class="headerlink" title="1、配置spark-env.sh"></a>1、配置spark-env.sh</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Cd /export/server/spark/conf</span><br><span class="line">Vi spark-env.sh</span><br></pre></td></tr></table></figure>
<p>加入以下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">## 设置JAVA安装目录</span><br><span class="line">JAVA_HOME=/export/server/jdk</span><br><span class="line"></span><br><span class="line">## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</span><br><span class="line">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line"></span><br><span class="line">## 指定spark老大Master的IP和提交任务的通信端口</span><br><span class="line"># 告知Spark的master运行在哪个机器上</span><br><span class="line"></span><br><span class="line"># 告知sparkmaster的通讯端口</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line"># 告知spark master的 webui端口</span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line"></span><br><span class="line"># worker cpu可用核数</span><br><span class="line">SPARK_WORKER_CORES=1</span><br><span class="line"># worker可用内存</span><br><span class="line">SPARK_WORKER_MEMORY=1g</span><br><span class="line"># worker的工作通讯地址</span><br><span class="line">SPARK_WORKER_PORT=7078</span><br><span class="line"># worker的 webui地址</span><br><span class="line">SPARK_WORKER_WEBUI_PORT=8081</span><br><span class="line"></span><br><span class="line">## 设置历史服务器</span><br><span class="line"># 配置的意思是  将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中</span><br><span class="line">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;</span><br><span class="line">SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;</span><br><span class="line"># spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现</span><br><span class="line"># 指定Zookeeper的连接地址</span><br><span class="line"># 指定在Zookeeper中注册临时节点的路径</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkha/1.png" alt="图 1"></p>
<h2 id="2、连接YARN"><a href="#2、连接YARN" class="headerlink" title="2、连接YARN"></a>2、连接YARN</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/pyspark --master yarn --deploy-mode client|cluster</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkha/2.png" alt="图 2"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master yarn --deploy-mode client|cluster</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkha/3.png" alt="图 3"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/09/Spark(Yarn)/" data-id="clj2k5f250002l0vf0h4wccs9" data-title="Spark(Yarn)" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark(HA)" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/09/Spark(HA)/" class="article-date">
  <time class="dt-published" datetime="2023-06-09T04:41:48.189Z" itemprop="datePublished">2023-06-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/09/Spark(HA)/">Spark(HA)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-首先配置spark-env-sh"><a href="#1-首先配置spark-env-sh" class="headerlink" title="1.首先配置spark-env.sh"></a>1.首先配置spark-env.sh</h2><p> 删除SPARK_MASTER_HOST&#x3D;node1这么操作的含义是不指定Master方便我们后续切换Master并在后面增加下面内容指定zookeeper</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;</span><br><span class="line"></span><br><span class="line"># spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现</span><br><span class="line"># 指定Zookeeper的连接地址</span><br><span class="line"># 指定在Zookeeper中注册临时节点的路径</span><br><span class="line"># 然后将spark分发到node2和node3中</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkha/1.png" alt="图"></p>
<h2 id="2-测试Spark-StandAloneHA"><a href="#2-测试Spark-StandAloneHA" class="headerlink" title="2.测试Spark StandAloneHA"></a>2.测试Spark StandAloneHA</h2><p>先在node1上启动一个master和全部的woiker</p>
<p>然后在node2上启动一个备用的maste</p>
<p><img src="/../sparkha/2.png" alt="图"><br><img src="/../sparkha/3.png" alt="图"></p>
<p>如图node1的状态是alive node2的状态是standy</p>
<p>提交一个任务到node1上的spark</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 1000</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkha/4.png" alt="图"></p>
<p>然后另起一台node1杀死node1的master<br><img src="/../sparkha/5.png" alt="图"></p>
<p>可以看到断开连接，等待一段时间。<br><img src="/../sparkha/6.png" alt="图"></p>
<p>发现程序执行成功代表我们的HA模式搭建成功。在node1的master出现问题崩溃掉的时候会自动切换到node2的备用master上使我们的程序不会崩溃。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/09/Spark(HA)/" data-id="clj2k5f240001l0vf0p31hbmw" data-title="Spark(HA)" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark(stand-alone)" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/09/Spark(stand-alone)/" class="article-date">
  <time class="dt-published" datetime="2023-06-09T04:41:48.188Z" itemprop="datePublished">2023-06-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/09/Spark(stand-alone)/">Spark(stand-alone)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Spark-StandAlone环境部署"><a href="#Spark-StandAlone环境部署" class="headerlink" title="Spark StandAlone环境部署"></a>Spark StandAlone环境部署</h2><p>进入到spark的配置文件目录中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd  spark/conf</span><br></pre></td></tr></table></figure>
<p>配置workers文件</p>
<p>改名, 去掉后面的.template后缀</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv workers.template workers</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkalone/1.png" alt="图 1"></p>
<p>编辑worker文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim workers</span><br></pre></td></tr></table></figure>
<p>将里面的localhost删除, 添加<br>node1<br>node2<br>node3<br>到workers文件内<br><img src="/../sparkalone/2.png" alt="图 2"></p>
<h2 id="配置spark-env-sh文件"><a href="#配置spark-env-sh文件" class="headerlink" title="配置spark-env.sh文件"></a>配置spark-env.sh文件</h2><h3 id="1-改名"><a href="#1-改名" class="headerlink" title="1. 改名"></a>1. 改名</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkalone/3.png" alt="图 3"></p>
<h3 id="2-编辑spark-env-sh-在底部追加如下内容"><a href="#2-编辑spark-env-sh-在底部追加如下内容" class="headerlink" title="2. 编辑spark-env.sh, 在底部追加如下内容"></a>2. 编辑spark-env.sh, 在底部追加如下内容</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">## 设置JAVA安装目录</span><br><span class="line">JAVA_HOME=/export/server/jdk</span><br><span class="line"></span><br><span class="line">## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</span><br><span class="line">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line"></span><br><span class="line">## 指定spark老大Master的IP和提交任务的通信端口</span><br><span class="line"># 告知Spark的master运行在哪个机器上</span><br><span class="line">export SPARK_MASTER_HOST=node1</span><br><span class="line"># 告知sparkmaster的通讯端口</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line"># 告知spark master的 webui端口</span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line"></span><br><span class="line"># worker cpu可用核数</span><br><span class="line">SPARK_WORKER_CORES=1</span><br><span class="line"># worker可用内存</span><br><span class="line">SPARK_WORKER_MEMORY=1g</span><br><span class="line"># worker的工作通讯地址</span><br><span class="line">SPARK_WORKER_PORT=7078</span><br><span class="line"># worker的 webui地址</span><br><span class="line">SPARK_WORKER_WEBUI_PORT=8081</span><br><span class="line"></span><br><span class="line">## 设置历史服务器</span><br><span class="line"># 配置的意思是  将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中</span><br><span class="line">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkalone/4.png" alt="图 4"></p>
<h2 id="在HDFS上创建程序运行历史记录存放的文件夹"><a href="#在HDFS上创建程序运行历史记录存放的文件夹" class="headerlink" title="在HDFS上创建程序运行历史记录存放的文件夹"></a>在HDFS上创建程序运行历史记录存放的文件夹</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /sparklog</span><br><span class="line">hadoop fs -chmod 777 /sparklog</span><br></pre></td></tr></table></figure>

<h2 id="配置spark-defaults-conf文件"><a href="#配置spark-defaults-conf文件" class="headerlink" title="配置spark-defaults.conf文件"></a>配置spark-defaults.conf文件</h2><h3 id="1-改名-1"><a href="#1-改名-1" class="headerlink" title="1. 改名"></a>1. 改名</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv spark-defaults.conf.template spark-defaults.conf</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkalone/5.png" alt="图 5"></p>
<h3 id="2-修改内容"><a href="#2-修改内容" class="headerlink" title="2. 修改内容"></a>2. 修改内容</h3><p>开启spark的日期记录功能</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled 	true</span><br></pre></td></tr></table></figure>
<p>设置spark日志记录的路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.dir	 hdfs://node1:8020/sparklog/ </span><br></pre></td></tr></table></figure>
<p>设置spark日志是否启动压缩</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.compress 	true</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkalone/6.png" alt="图 6"></p>
<h2 id="配置log4j-properties-文件"><a href="#配置log4j-properties-文件" class="headerlink" title="配置log4j.properties 文件"></a>配置log4j.properties 文件</h2><p>改名</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv log4j.properties.template log4j.properties</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkalone/7.png" alt="图 7"></p>
<p>将Spark安装文件夹  分发到其它的服务器上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r spark-3.1.2-bin-hadoop3.2 node2:/export/server/</span><br><span class="line">scp -r spark-3.1.2-bin-hadoop3.2 node3:/export/server/</span><br></pre></td></tr></table></figure>
<p>分别在node2，node3设置软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /export/server/spark-3.1.2-bin-hadoop3.2 /export/server/spark</span><br></pre></td></tr></table></figure>
<p>启动历史服务器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-history-server.sh</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkalone/8.png" alt="图 8"></p>
<h2 id="启动Spark的Master和Worker进程"><a href="#启动Spark的Master和Worker进程" class="headerlink" title="启动Spark的Master和Worker进程"></a>启动Spark的Master和Worker进程</h2><p>启动全部master和worker</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></figure>
<p>#或者可以一个个启动:<br>启动当前机器的master</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-master.sh</span><br></pre></td></tr></table></figure>
<p>启动当前机器的worker</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-worker.sh</span><br></pre></td></tr></table></figure>
<p>停止全部</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-all.sh</span><br></pre></td></tr></table></figure>
<p>停止当前机器的master</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-master.sh</span><br></pre></td></tr></table></figure>
<p>停止当前机器的worker</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-worker.sh</span><br></pre></td></tr></table></figure>
<p>查看Master的WEB UI<br><img src="/../sparkalone/9.png" alt="图 9"></p>
<p>连接到StandAlone集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/pyspark --master spark://node1:7077</span><br></pre></td></tr></table></figure>
<p><img src="/../sparkalone/10.png" alt="图 10"></p>
<p>查看历史服务器WEB UI</p>
<p>输入node1:18080</p>
<p><img src="/../sparkalone/11.png" alt="图 11"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/09/Spark(stand-alone)/" data-id="clj2k5f280006l0vfg6tt7iqj" data-title="Spark(stand-alone)" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Git" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/09/Git/" class="article-date">
  <time class="dt-published" datetime="2023-06-09T04:28:42.455Z" itemprop="datePublished">2023-06-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/09/Git/">Git</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1、安装"><a href="#1、安装" class="headerlink" title="1、安装"></a>1、安装</h2><p>下载地址： <a target="_blank" rel="noopener" href="https://git-scm.com/download%EF%BC%8C%E9%80%89%E6%8B%A9Windows%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8B%E8%BD%BD">https://git-scm.com/download，选择Windows操作系统下载</a></p>
<p><img src="/../git/1.jpg" alt="图"></p>
<p>安装过程中需要注册，填写用户名及邮箱</p>
<p><img src="/../git/2.jpg" alt="图"></p>
<p>注：安装完成后需要手动重启资源管理器或重启电脑。</p>
<h2 id="2、Git初始化"><a href="#2、Git初始化" class="headerlink" title="2、Git初始化"></a>2、Git初始化</h2><p>初始化一个本地仓</p>
<p>选择新建的git_test文件，右键单机，选择Git在这里创建版本库</p>
<p> <img src="/../git/3.jpg" alt="图"><br> <img src="/../git/4.jpg" alt="图"><br> <img src="/../git/5.jpg" alt="图"></p>
<p>操作后可以发现在git_test文件图标上出现了绿色的小勾，说明本地仓库创建成功，在进入该文件夹后还可以发现一个.git文件。此时，git初始化仓库就完成了。</p>
<p><img src="/../git/6.jpg" alt="图"></p>
<h2 id="3、概念即详解"><a href="#3、概念即详解" class="headerlink" title="3、概念即详解"></a>3、概念即详解</h2><p>图中有远程仓库、本地仓库、工作区以及暂存区。<br>本地仓库：是在开发人员自己电脑上的Git仓库,存放我们的代码。<br>远程仓库：是在远程服务器上的Git仓库，一般是上传至企业的代码总仓库。<br>工作区: 我们自己编写代码的区域。<br>暂存区: 在本地仓库中的一个特殊的文件叫做暂存区,用来临时存储我们即将要提交的文件。</p>
<h2 id="4、Git的操作"><a href="#4、Git的操作" class="headerlink" title="4、Git的操作"></a>4、Git的操作</h2><p>Clone：克隆，就是将远程仓库复制到本地仓库。<br>Push：推送，就是将本地仓库代码上传到远程仓库。<br>Pull：拉取，就是将远程仓库代码下载到本地仓库，并将代码克隆到本地工作区。</p>
<h2 id="5、Git下的文件存在的状态"><a href="#5、Git下的文件存在的状态" class="headerlink" title="5、Git下的文件存在的状态"></a>5、Git下的文件存在的状态</h2><p>1、untracked 未跟踪: 比如新建的文件(此时文件夹上没有图标或者有一个”问号”)</p>
<p>2、uracked 已跟踪:</p>
<p>(1)Staged 已暂存状态:添加 但未提交状态(此时文件夹上有一个”加号”)</p>
<p>(2)Unmodified 未修改状态:已提交(此时文件夹上有一个”对号”)</p>
<p>(3)Modified 已修改状态:修改了,但是还没有提交 (此时文件夹上有一个”红色感叹号”)</p>
<p><img src="/../git/7.jpg" alt="图"><br><img src="/../git/8.jpg" alt="图"><br><img src="/../git/9.jpg" alt="图"></p>
<p>3、如再次对文件进行修改，文件图表旁会出现一个红色的叹号。</p>
<p><img src="/../git/10.jpg" alt="图"><br><img src="/../git/11.jpg" alt="图"><br><img src="/../git/12.jpg" alt="图"><br><img src="/../git/13.jpg" alt="图"></p>
<p>4、回退至历史版本等操作</p>
<p><img src="/../git/14.jpg" alt="图"><br><img src="/../git/15.jpg" alt="图"></p>
<p>5、忽略提交</p>
<p><img src="/../git/16.jpg" alt="图"><br><img src="/../git/17.jpg" alt="图"></p>
<p>6、分支</p>
<p>单线程开发</p>
<p><img src="/../git/18.jpg" alt="图"><br><img src="/../git/19.jpg" alt="图"></p>
<p>7、创建分支 主分支(master)</p>
<p><img src="/../git/20.jpg" alt="图"></p>
<p>8、查看分支</p>
<p><img src="/../git/21.jpg" alt="图"></p>
<p>9、切换分支</p>
<p><img src="/../git/22.jpg" alt="图"></p>
<p>10、分支的合并与删除 切换到主版本 右键 合并即可将需求1写的代码合并至主分支</p>
<p><img src="/../git/23.jpg" alt="图"></p>
<p>11、删除分支</p>
<p><img src="/../git/24.jpg" alt="图"></p>
<p>12、代码合并时会报错,我们叫做冲突</p>
<p><img src="/../git/25.jpg" alt="图"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/09/Git/" data-id="clj2k5f1v0000l0vfd8uq05h8" data-title="Git" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Docker" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/09/Docker/" class="article-date">
  <time class="dt-published" datetime="2023-06-09T02:16:33.261Z" itemprop="datePublished">2023-06-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/09/Docker/">Docker</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一-需要虚拟机联网，安装yum工具"><a href="#一-需要虚拟机联网，安装yum工具" class="headerlink" title="一.  需要虚拟机联网，安装yum工具"></a>一.  需要虚拟机联网，安装yum工具</h2><p><img src="/../Docker/1.png" alt="图 1"></p>
<h2 id="二-配置网卡转发"><a href="#二-配置网卡转发" class="headerlink" title="二.	配置网卡转发"></a>二.	配置网卡转发</h2><h3 id="1-docker必须安装在centos7平台，内核版本不低于3-10在centos平台运行docker可能会遇见些告警信息，修改内核配置参数，打开内核转发功能"><a href="#1-docker必须安装在centos7平台，内核版本不低于3-10在centos平台运行docker可能会遇见些告警信息，修改内核配置参数，打开内核转发功能" class="headerlink" title="1.docker必须安装在centos7平台，内核版本不低于3.10在centos平台运行docker可能会遇见些告警信息，修改内核配置参数，打开内核转发功能"></a>1.docker必须安装在centos7平台，内核版本不低于3.10在centos平台运行docker可能会遇见些告警信息，修改内核配置参数，打开内核转发功能</h3><p>写入<br><img src="/../Docker/2.png" alt="图 2"></p>
<h3 id="2-重新加载内核参数"><a href="#2-重新加载内核参数" class="headerlink" title="2.重新加载内核参数"></a>2.重新加载内核参数</h3><p><img src="/../Docker/3.png" alt="图 3"></p>
<h2 id="三-利用yum进行docker安装"><a href="#三-利用yum进行docker安装" class="headerlink" title="三.	利用yum进行docker安装"></a>三.	利用yum进行docker安装</h2><h3 id="提前配置好yum仓库"><a href="#提前配置好yum仓库" class="headerlink" title="提前配置好yum仓库"></a>提前配置好yum仓库</h3><h3 id="阿里云自带仓库-2-阿里云提供的docker专属repo仓库"><a href="#阿里云自带仓库-2-阿里云提供的docker专属repo仓库" class="headerlink" title="阿里云自带仓库 2.阿里云提供的docker专属repo仓库"></a>阿里云自带仓库 2.阿里云提供的docker专属repo仓库</h3><p><img src="/../Docker/4.png" alt="图 4"><br><img src="/../Docker/5.png" alt="图 5"></p>
<h3 id="更新yum缓存"><a href="#更新yum缓存" class="headerlink" title="更新yum缓存"></a>更新yum缓存</h3><p><img src="/../Docker/6.png" alt="图 6"></p>
<h3 id="可以直接yum安装docker了"><a href="#可以直接yum安装docker了" class="headerlink" title="可以直接yum安装docker了"></a>可以直接yum安装docker了</h3><p>查看源中可用版本<br><img src="/../Docker/7.png" alt="图 7"></p>
<p>yum的安装<br><img src="/../Docker/8.png" alt="图 8"><br><img src="/../Docker/9.png" alt="图 9"></p>
<p>查看docker版本，验证是否验证成功<br><img src="/../Docker/10.png" alt="图 10"></p>
<p>如果要卸载</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum remove -y docker-ce-xxx</span><br></pre></td></tr></table></figure>

<h2 id="四-配置镜像加速器"><a href="#四-配置镜像加速器" class="headerlink" title="四.	配置镜像加速器"></a>四.	配置镜像加速器</h2><h3 id="用于加速镜像文件下载-选用阿里云镜像站"><a href="#用于加速镜像文件下载-选用阿里云镜像站" class="headerlink" title="用于加速镜像文件下载,选用阿里云镜像站"></a>用于加速镜像文件下载,选用阿里云镜像站</h3><p><img src="/../Docker/11.png" alt="图 11"></p>
<h2 id="五-启动docker"><a href="#五-启动docker" class="headerlink" title="五.	启动docker"></a>五.	启动docker</h2><h3 id="启动docker前，一定要关闭防火墙后！！"><a href="#启动docker前，一定要关闭防火墙后！！" class="headerlink" title="启动docker前，一定要关闭防火墙后！！"></a>启动docker前，一定要关闭防火墙后！！</h3><h3 id="关闭"><a href="#关闭" class="headerlink" title="关闭"></a>关闭</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure>

<h3 id="禁止开机启动防火墙"><a href="#禁止开机启动防火墙" class="headerlink" title="禁止开机启动防火墙"></a>禁止开机启动防火墙</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>

<h3 id="通过命令启动docker："><a href="#通过命令启动docker：" class="headerlink" title="通过命令启动docker："></a>通过命令启动docker：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#systemctl start docker  # 启动docker服务</span><br><span class="line">#systemctl stop docker  # 停止docker服务</span><br><span class="line">#systemctl restart docker  # 重启docker服务</span><br></pre></td></tr></table></figure>

<h3 id="我们使用如下命令进行docker启动"><a href="#我们使用如下命令进行docker启动" class="headerlink" title="我们使用如下命令进行docker启动"></a>我们使用如下命令进行docker启动</h3><p>docker配置文件重新加载<br><img src="/../Docker/12.png" alt="图 12"></p>
<p>查看docker信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker info</span><br><span class="line">docker ps</span><br><span class="line">docker images</span><br><span class="line">docker version</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/13.png" alt="图 13"><br><img src="/../Docker/14.png" alt="图 14"><br><img src="/../Docker/15.png" alt="图 15"><br><img src="/../Docker/16.png" alt="图 16"></p>
<p>docker-client</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">which docker</span><br></pre></td></tr></table></figure>
<p>docker daemon</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux |grep docker</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/17.png" alt="图 17"></p>
<p>containerd</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux|grep containerd</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/18.png" alt="图 18"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl status containerd</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/19.png" alt="图 19"></p>
<h2 id="Docker初体验"><a href="#Docker初体验" class="headerlink" title="Docker初体验"></a>Docker初体验</h2><h3 id="1-查看本地的docker镜像有哪些"><a href="#1-查看本地的docker镜像有哪些" class="headerlink" title="1.查看本地的docker镜像有哪些"></a>1.查看本地的docker镜像有哪些</h3><p><img src="/../Docker/20.png" alt="图 20"></p>
<h3 id="2-可选择删除旧版本"><a href="#2-可选择删除旧版本" class="headerlink" title="2.可选择删除旧版本"></a>2.可选择删除旧版本</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi 镜像id</span><br></pre></td></tr></table></figure>

<h3 id="3-搜索一下远程仓库中的镜像文件是否存在"><a href="#3-搜索一下远程仓库中的镜像文件是否存在" class="headerlink" title="3.搜索一下远程仓库中的镜像文件是否存在"></a>3.搜索一下远程仓库中的镜像文件是否存在</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker search nginx</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/21.png" alt="图 21"></p>
<h3 id="4-拉取，下载镜像"><a href="#4-拉取，下载镜像" class="headerlink" title="4.拉取，下载镜像"></a>4.拉取，下载镜像</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/22.png" alt="图 22"></p>
<h3 id="5-再次查看镜像"><a href="#5-再次查看镜像" class="headerlink" title="5.再次查看镜像"></a>5.再次查看镜像</h3><p><img src="/../Docker/23.png" alt="图 23"></p>
<h3 id="6-运行镜像，运行出具体内容，在容器中就跑着一个nginx服务"><a href="#6-运行镜像，运行出具体内容，在容器中就跑着一个nginx服务" class="headerlink" title="6.运行镜像，运行出具体内容，在容器中就跑着一个nginx服务"></a>6.运行镜像，运行出具体内容，在容器中就跑着一个nginx服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run 参数 镜像的名字/id</span><br></pre></td></tr></table></figure>

<p>-d 后台运行容器</p>
<p>-p 80:80 端口映射，宿主机端口：容器内端口，访问宿主机的80端口，也就访问到容器中的80端口</p>
<p>返回一个容器的id</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 80:80 nginx</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/24.png" alt="图 24"></p>
<h3 id="7-查看容器是否在运行"><a href="#7-查看容器是否在运行" class="headerlink" title="7.查看容器是否在运行"></a>7.查看容器是否在运行</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/25.png" alt="图 25"></p>
<h3 id="8-访问网站"><a href="#8-访问网站" class="headerlink" title="8.访问网站"></a>8.访问网站</h3><p><img src="/../Docker/26.png" alt="图 26"></p>
<h3 id="9-停止容器"><a href="#9-停止容器" class="headerlink" title="9.停止容器"></a>9.停止容器</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop 容器id</span><br></pre></td></tr></table></figure>
<p><img src="/../Docker/27.png" alt="图 27"></p>
<h3 id="10-恢复容器"><a href="#10-恢复容器" class="headerlink" title="10.恢复容器"></a>10.恢复容器</h3><p><img src="/../Docker/28.png" alt="图 28"></p>
<h2 id="用docker切换不同发行版本，内核都为宿主机内核"><a href="#用docker切换不同发行版本，内核都为宿主机内核" class="headerlink" title="用docker切换不同发行版本，内核都为宿主机内核"></a>用docker切换不同发行版本，内核都为宿主机内核</h2><h3 id="1-利用docker获取不同的发行版镜像"><a href="#1-利用docker获取不同的发行版镜像" class="headerlink" title="1.利用docker获取不同的发行版镜像"></a>1.利用docker获取不同的发行版镜像</h3><p><img src="/../Docker/29.png" alt="图 29"><br><img src="/../Docker/30.png" alt="图 30"></p>
<h3 id="2-确认当前宿主机的发行版"><a href="#2-确认当前宿主机的发行版" class="headerlink" title="2.确认当前宿主机的发行版"></a>2.确认当前宿主机的发行版</h3><p><img src="/../Docker/31.png" alt="图 31"></p>
<h3 id="3-运行centos-7-8-2003发行版本"><a href="#3-运行centos-7-8-2003发行版本" class="headerlink" title="3.运行centos:7.8.2003发行版本"></a>3.运行centos:7.8.2003发行版本</h3><p>运行容器，且进入容器内部</p>
<p>参数解释，-i 交互式命令操作 -t 开启一个终端 bash 进入容器后执行的命令<br><img src="/../Docker/32.png" alt="图 32"></p>
<p>一个完整的系统，是由linux的内核+发行版，才组成了一个可以使用的完整的系统</p>
<p>利用docker容器，可以获取不同的发行版镜像，然后基于该镜像，运行出各种容器去使用</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/09/Docker/" data-id="clj2k5f260004l0vf59v517lu" data-title="Docker" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark(local)" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/09/Spark(local)/" class="article-date">
  <time class="dt-published" datetime="2023-06-09T01:45:14.380Z" itemprop="datePublished">2023-06-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/09/Spark(local)/">Spark(local)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-安装Python环境到windows上"><a href="#1-安装Python环境到windows上" class="headerlink" title="1.安装Python环境到windows上"></a>1.安装Python环境到windows上</h2><p>Windows系统配置Anaconda</p>
<p>打开资料中提供的:Anaconda3-2021.05-Windows-x86_64.exe文件</p>
<p>配置国内源加速网络下载</p>
<p>打开C:\Users\用户名.condarc文件</p>
<p>将以下内容进行替换；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line">default_channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure>
<h2 id="2-安装Python环境需要安装到Linux"><a href="#2-安装Python环境需要安装到Linux" class="headerlink" title="2.安装Python环境需要安装到Linux"></a>2.安装Python环境需要安装到Linux</h2><p>创建虚拟环境 pyspark, 基于Python 3.8</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n pyspark python=3.8</span><br></pre></td></tr></table></figure>
<p><img src="/../sparklocal/1.png" alt="图 1"></p>
<p>换到虚拟环境内</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate pyspark</span><br></pre></td></tr></table></figure>
<p><img src="/../sparklocal/2.png" alt="图 2"></p>
<p>在虚拟环境内安装包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>
<p><img src="/../sparklocal/3.png" alt="图 3"></p>
<h2 id="3-解压下载的Spark安装包"><a href="#3-解压下载的Spark安装包" class="headerlink" title="3. 解压下载的Spark安装包"></a>3. 解压下载的Spark安装包</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</span><br></pre></td></tr></table></figure>
<p><img src="/../sparklocal/4.png" alt="图 4"></p>
<p>配置环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#HADOOP_HOME</span><br><span class="line">export SPARK_HOME=/export/server/spark</span><br><span class="line"></span><br><span class="line">#PYSPARK_PYTHON</span><br><span class="line">export PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python</span><br><span class="line"></span><br><span class="line">#HADOOP_CONF_DIR</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line"></span><br><span class="line">#ZOOKEEPER_HOME</span><br><span class="line">export ZOOKEEPER_HOME=/export/server/zookeeper</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_2</span><br></pre></td></tr></table></figure>
<p>重置环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Source /etc/profile</span><br><span class="line">PYSPARK_PYTHON和 JAVA_HOME 需要同样配置在: `/root/.bashrc`中</span><br></pre></td></tr></table></figure>
<p><img src="/../sparklocal/5.png" alt="图 5"></p>
<p>上传文件到Linux服务器中<br>解压文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</span><br></pre></td></tr></table></figure>
<p><img src="/../sparklocal/6.png" alt="图 6"></p>
<p>设置软链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</span><br></pre></td></tr></table></figure>
<p><img src="/../sparklocal/7.png" alt="图 7"></p>
<p>进去pyspark<br><img src="/../sparklocal/8.png" alt="图 8"></p>
<p>测试<br><img src="/../sparklocal/9.png" alt="图 9"></p>
<p>打开服务器4040<br><img src="/../sparklocal/10.png" alt="图 10"></p>
<p>Jps查看<br><img src="/../sparklocal/11.png" alt="图 11"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/09/Spark(local)/" data-id="clj2k5f270005l0vf6fq7fpke" data-title="Spark(local)" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>
</section>
        <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/06/19/zookeeper/">Zookeeper</a>
          </li>
        
          <li>
            <a href="/2023/06/19/kafka/">Kafka</a>
          </li>
        
          <li>
            <a href="/2023/06/19/sqoop/">Sqoop</a>
          </li>
        
          <li>
            <a href="/2023/06/19/flume/">Flume</a>
          </li>
        
          <li>
            <a href="/2023/06/09/Spark(Yarn)/">Spark(Yarn)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li></ul>
    </div>
  </div>

  
</aside>
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 By Autoload<br>
      Driven - <a href="https://hexo.io/" target="_blank">Hexo</a>|Theme - <a href="https://github.com/autoload/hexo-theme-auto" target="_blank">Auto</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>